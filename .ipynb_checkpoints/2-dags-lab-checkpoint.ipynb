{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "saving-customs",
   "metadata": {},
   "source": [
    "# Dags Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-clause",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-carroll",
   "metadata": {},
   "source": [
    "In this lesson, we'll practice creating our own DAGs in Airflow.  We'll set up a workflow that can make a request to our texas drink receipts API available [here](https://data.texas.gov/dataset/Mixed-Beverage-Gross-Receipts/naix-2893), and then select information from that requested data.  We'll do so by first setting up tasks that fake the request to the drink receipts API, and then when this is working, we'll make the request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5ef08-ee74-49e2-b439-b9240eb821fd",
   "metadata": {},
   "source": [
    "## Setting up docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431cdd1-5c9b-4367-9b5e-066f565ad86b",
   "metadata": {},
   "source": [
    "Begin by creating a directory called `texas_drinks_workflow`.  Then curl down the docker-compose file to boot up airflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20be0d-6bc6-4eb0-b52b-7674554f4c69",
   "metadata": {},
   "source": [
    "```bash\n",
    "curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.0.1/docker-compose.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a08ae70-1360-4c15-ba6c-7ebb7676a7fa",
   "metadata": {},
   "source": [
    "Now, before booting up airflow, it's a good idea to alter our docker-compose file by going to our docker compose file, and doing the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec50e2-1096-4a34-99fa-58ccd90f7769",
   "metadata": {},
   "source": [
    "> Look for the line that says `AIRFLOW__CORE__LOAD_EXAMPLES`. Change the value 'true' to 'false'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd71736-3b61-4281-93c2-6128d2b9db9c",
   "metadata": {},
   "source": [
    "From here we should create a folder called `dags` where we can place our dags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-outline",
   "metadata": {},
   "source": [
    "### Creating a Dag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-soundtrack",
   "metadata": {},
   "source": [
    "Let's begin by creating a DAG with the id of `get_tax_receipts`.  Then, let's check our work.  \n",
    "\n",
    "Use docker to boot up an airflow webserver connected to the dags folder with our new dag.  we can check this in two ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-lindsay",
   "metadata": {},
   "source": [
    "* First, we can make sure that the dag is loaded into the correct folder by sh-ing into the docker container, and then looking in the `/usr/local/airflow/dags` folder.\n",
    "\n",
    "> You need to do this from the folder of texas_drinks_workflow.  Then you can connect to the container by first listing the docker-compose services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6693229-488a-45a1-a2e8-5270316e4517",
   "metadata": {},
   "source": [
    "<img src=\"./list-services.png\" width=\"90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d4918-8b10-46ba-80b7-3075bd0ed988",
   "metadata": {},
   "source": [
    "And then sh-ing into the relevant contianer -- here the webserver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bcfbf-0831-4fe0-8085-eae02a96319b",
   "metadata": {},
   "source": [
    "<img src=\"./connect-api.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd7a7b-e4f7-48bb-892d-e5437f197d09",
   "metadata": {},
   "source": [
    "From there, we should be able to view our dag in the dags folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2baba4-43a7-4568-85d6-6b679f455e50",
   "metadata": {},
   "source": [
    "<img src=\"./dags-folder.png\" width=\"90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-boston",
   "metadata": {},
   "source": [
    "* Second, let's go our airflow website and hopefully see our dag appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-miniature",
   "metadata": {},
   "source": [
    "<img src=\"./get-tax-receipts.png\" width=\"70%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-reaction",
   "metadata": {},
   "source": [
    "The next step is to add a `start_date` to the dag.  Set the start date as five days previous to the current time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-battle",
   "metadata": {},
   "source": [
    "> You can refresh the dagbag with the following:\n",
    "* ```python -c \"from airflow.models import DagBag; d = DagBag();\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-league",
   "metadata": {},
   "source": [
    "The next time we boot up our webserver, we can check that airflow saw the changes by hovering over the three dots under the word `links`, and then clicking on code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-insertion",
   "metadata": {},
   "source": [
    "> <img src=\"./click-code.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-sunglasses",
   "metadata": {},
   "source": [
    "Then turn on the dag run with the off-on switch over to the left, and shortly thereafter, we should see the dag run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-probe",
   "metadata": {},
   "source": [
    "<img src=\"./five-runs.png\" width=\"90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-telling",
   "metadata": {},
   "source": [
    "Now if you click on the green DAG runs button, eventually, you can see five successes.  The reason is because there is a default time interval that the dag should be run every day, and we placed the start date as 5 days ago.  So airflow will run the dag five times to try to backfill.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-blues",
   "metadata": {},
   "source": [
    "<img src=\"./dag-run-history.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-spell",
   "metadata": {},
   "source": [
    "Let's setup the dag so that it only runs once -- we can do that by setting the `start_date` as one day in the past.  Make that change now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-storage",
   "metadata": {},
   "source": [
    "### Adding Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-guard",
   "metadata": {},
   "source": [
    "Ok, now so far we have created a DAG, but we have not added any tasks to that dag.  Let's do that now.  \n",
    "\n",
    "* First add a task called `retrieve_receipts`.  For now, the task will not actually retreive the receipts from the api.  Instead, we should just see the string `getting receipts` in the logs when we run the dag -- you can do this with a print statement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-falls",
   "metadata": {},
   "source": [
    "After making the change, first delete the existing dag from via the airflow webserver -- by clicking on the red trash can.\n",
    "\n",
    "<img src=\"./delete-dag.png\" width=\"70%\">\n",
    "\n",
    "Then refresh the dag bag.  \n",
    "\n",
    "`python -c \"from airflow.models import DagBag; d = DagBag();\"`\n",
    "\n",
    "Then, if we click on the `get_tax_receipts` dag, we should see something like the task listed there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-medline",
   "metadata": {},
   "source": [
    "> <img src=\"./with_task.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-customer",
   "metadata": {},
   "source": [
    "Then if we flip the DAG on, we should see both the dag, and the related task running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-wholesale",
   "metadata": {},
   "source": [
    "> Take a look under the Recent Tasks tab to see whether it run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-delight",
   "metadata": {},
   "source": [
    "> <img src=\"./run-dag.png\" width=\"80%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-yesterday",
   "metadata": {},
   "source": [
    "From there, let's check the green circle under recent tasks, then click on the task id, and look at the logs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c6cf3-f4ea-4e5d-a697-abb671ba84f1",
   "metadata": {},
   "source": [
    "> <img src=\"./log-task.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b5a72-841b-4044-b75b-32685470dc71",
   "metadata": {},
   "source": [
    "We should see something like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-admission",
   "metadata": {},
   "source": [
    "> <img src=\"./get_receipts_log.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-bicycle",
   "metadata": {},
   "source": [
    "> Notice that in the second to last line it says the returned value was `getting receipts`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-shakespeare",
   "metadata": {},
   "source": [
    "### Adding another task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-warren",
   "metadata": {},
   "source": [
    "Now let's add another task called `find_large_receipts` that returns `found large receipts` when run.  And have the `retreive_receipts` and then the `finding_receipts` step be called in sequential order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-module",
   "metadata": {},
   "source": [
    "After shutting down the docker container and restarting it, we should now see the following under the Dag's tree view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-dialogue",
   "metadata": {},
   "source": [
    "> <img src=\"./dag-sequential.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-jacob",
   "metadata": {},
   "source": [
    "Notice that with this updated diagram, that `get_receipts` is run followed by `find_receipts`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-earth",
   "metadata": {},
   "source": [
    "Next, let's switch on the dag, and check that both of these tasks are run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-point",
   "metadata": {},
   "source": [
    "> The recent tasks panel should show two, with a green circle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-official",
   "metadata": {},
   "source": [
    "> <img src=\"./two-run.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-colorado",
   "metadata": {},
   "source": [
    "If we click on the recent tasks circle, we should be able to take a look at the logs of each tasks to see that the correct values were properly returned.\n",
    "\n",
    "> So the `find_receipts` task should produce logs like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-chrome",
   "metadata": {},
   "source": [
    "> <img src=\"./found_large_receipts.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-thursday",
   "metadata": {},
   "source": [
    "In the third to last line, we can see that it says `found large receipts` were returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-bloom",
   "metadata": {},
   "source": [
    "### Working with Schedule Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-criminal",
   "metadata": {},
   "source": [
    "Now let's change how often our dag is run.  We can do this with the schedule interval.  Update the dag so that it sets a schedule interval to daily, by adding the following keyword argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-footwear",
   "metadata": {},
   "source": [
    "```python\n",
    "schedule_interval='@hourly'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-january",
   "metadata": {},
   "source": [
    "We can see the various options for setting how often the dag will be run with the [presets documentation](https://airflow.apache.org/docs/apache-airflow/stable/dag-run.html#cron-presets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-viking",
   "metadata": {},
   "source": [
    "### Make it real(er)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-deficit",
   "metadata": {},
   "source": [
    "Ok, now let's have our `get_receipts` task connect to our Texas Drinks API.  The url to reach is the following:\n",
    "\n",
    "`https://data.texas.gov/resource/naix-2893.json?taxpayer_zip=77036`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-supplier",
   "metadata": {},
   "source": [
    "And next time when we run the dag, have that task return the first dictionary from the api.  If it's done properly, the log should look something like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-gravity",
   "metadata": {},
   "source": [
    "<img src=\"./returned_api_value.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-edgar",
   "metadata": {},
   "source": [
    "> So we can see the `Returned value was:` had the dictionary with the `taxpayer_number` and `name`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-upgrade",
   "metadata": {},
   "source": [
    "### Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-budget",
   "metadata": {},
   "source": [
    "If you would like to store the data, perhaps write the data to a csv file in the first task, and then read the data from that csv returning receipts greater than zero in the second task.  Look at using pandas to do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-portfolio",
   "metadata": {},
   "source": [
    "* For writing to csv we can do something like the following: \n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(response.json())\n",
    "df.to_csv('records.csv')\n",
    "```\n",
    "\n",
    "And for reading from csv and getting back a list of dictionaries to search through we can do something like the following: \n",
    "\n",
    "```python    \n",
    "df = pd.read_csv('./records.csv')\n",
    "records = df.to_dict('records.csv')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-exposure",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-moore",
   "metadata": {},
   "source": [
    "In this lab, we practiced working with directed acyclic graphs.  We saw that we could initialize a DAG, and then add tasks to the DAG.  Then we moved into specifying a schedule interval with the dag, by adding the `schedule_interval` keyword argument and the preset of `'@hourly'`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
